EN

My idea for an artificial method of improving the image or video quality would be that the image frame would be processed from simple pixels in a plus system and seen as a honeycomb, i.e. from a plus to one honeycomb cell, or from a parallel equilateral octagon - such as a stop sign from those obtained information, it will be much easier to scale 2x or 4x, you can first scale 2x and then repeat the processing but attention,

In this way, there would be distortions in the adjacent slices, so when combining them together, the average color spectrum must be obtained and returned to the top ones, i.e. those external adjoining fields (which would not be original anymore because the image was previously doubled) but this is not it looks logical on the example of a plus, also this sample would have to be such a double-pointed plus before the mathematical process of making these triangles resulting from the sum of the visible light spectrum of neighboring blocks / pixels And probably it would be better to scale the image first without algorithms, i.e. by doubling everything or times a number, and then only apply that's all. dividing the image into plus fields with a connecting element and summarizing the colors in the fields, I figured out that this is not exactly what the honeycomb looks like, the structure of which I wanted to get with a plus, it would be enough to add a half-arm connector that would eventually also become one with two arms As you can see in this simplest example, the image will be 60% enlarged because 4 triangles of a half square = 2 fields + 2 halves of a square = 1 field total 3 and originally plus consisted of 5 fields together gives 8 fields and this is 8 to 5, i.e. 16 to 10 = 1.6 times the size of the image, i.e. 1920 x 1.6 = 3072 pixels widh 1728 height 3072x1728 for example, the resolution of 3k is 2880x1620. add to this good postprocessing I would suggest based on smoothing with the help of the brightness factor in order to obtain the appropriate depth and hide visible imperfections. and from the fullhd picture you get a nice picture for a 4K screen 6 times the size of the image, i.e. 1920 x 1.6 = 3072 pixels. Widh 1728 height 3072x1728, for example, the resolution of 3k is 2880x1620. add to this good postprocessing I would suggest based on smoothing with the help of the brightness factor in order to obtain the appropriate depth and hide visible imperfections. and from the fullhd picture you get a nice picture for a 4K screen 6 times the size of the image, i.e. 1920 x 1.6 = 3072 pixels. Widh 1728 height 3072x1728, for example, the resolution of 3k is 2880x1620. add to this good postprocessing I would suggest based on smoothing with the help of the brightness factor in order to obtain the appropriate depth and hide visible imperfections. and from the fullhd picture you get a nice picture for a 4K screen

https://github.com/devegoo/VED_CODE4CODEC4SCALE/blob/main/resample_01.gif here are shown upscaling algorithms for x2 which gives twice the surface but whether the quality is appropriate, my method, the one I showed some time ago, has a factor of x1.6 in one pass, not doubling, and how would I see pushing up if my algorithm precedes the action like here, i.e. first doubling, for example, with the Lanczos IrfanView algorithm and then pushing or vice versa, it depends on what will be better in visual tests, the magnification factor will be x2 x1.6 or x3.2 and my algorithm in two runs 1x1.6x1.6 = 2.56 and such scaling with my algorithm of material with SD resolution in 2 passes, ie 720x480, for example: 720x2.56 = 1843.2 | 480x2.56 = 1228.8 (1920 x1080 is FHD).

PL

Mój pomysł na sztuczną metode podnoszenia jakości obrazu lub wideo polegałby na tym że klatka obrazu byłaby przetwarzana z prostych pikseli w układzie plus i widziana jak plaster miodu czyli z plusa na jedną komórkę plastra miodu cz też ośmiooboku równobocznego równoległego - taki jak znak stop a z tych otrzymanych informacji już bedzie znacznie łatwiej skalować 2x czy 4x, można najpierw skalować 2x a pożniej powtórzyć przetwarzanie ale uwaga , 

tym sposobem doszło by do przekłamań w sąsiadujących plastrach dla tego podczas łaczenia ich w całość musi dojść do uzyskiwania średniej widma koloru i oddania go spowrotem do  wierzchołkowych czyli tych zewnetrznych stykających się pól (które już nie byłyby oryginalnymi bo obraz był wcześniej podwojony) ale to nie logicznie wygląda na przykładzie plusa takżę ta próbka musiałaby byc takim podwójnoramiennym  plusem przed procesem matematycznym dorabiania tych trójkątów powstałych z sumy widma światła widzialnego sąsiednich bloków/pikseli 
I chyba jednak najpierw by było lepiej przeskalować obraz bez algorytmów czyli podwajając wszystko lub razy ileśtam a pożniej dopiero zastosować to wszystko.
podział obrazu na pola plusowe z elementem łączącym i sumaryzacja kolorów w polach, kapnołem się że tak nie dokładnie wygląda plaster miodu ktorego struktore chcialem uzyskac z plusa to wystrczy taki pol ramienny łącznik dorobic ktory ostatecznie tez z dwuch ramion stanie sie jednym
Jak widać na tym najprostszym przykładzie obraz bedzie o   60% powiększony bo 4 trojkąty połowki kwadratu = 2 pola + 2 połówki kwadratu = 1 pole razem 3 a pierwotnie plus skladał sie z 5 pól razem daje 8 pól a to 8 do 5 czyli 16 do 10 = 1,6 razy większy rozmiar obrazu czyli 1920 x 1.6 = 3072 pixeli widh 1728 height
3072x1728 dla przykładu rozdzielczość 3k wynosi 2880x1620.
dodać do tego dobry postprocessing ja bym proponował bazujący na wygładzaniu przy pomocy  współczynnika jasnośći aby otrzymać odpowidnią głebie i ukryć dostrzegalne niedoskonałości. i z obrazu fullhd otrzymuje sie ładny obraz dl ekranu 4K

https://github.com/devegoo/VED_CODE4CODEC4SCALE/blob/main/resample_01.gif
tu są pokazane algorytmy upscalingu dla x2 co daje dwa razy większą powierzchnie ale czy jakość jest przy tym odpowiednia, mój sposób ten który pokazałem jakiś czas temu ma wsþółczynnik x1.6 w jednym przebiegu nie podwajania a jakbym to powidział rozpychania się , jeśli mój algorytm poprzedzi tak akcja jak tu czyli najpierw podwojenie np algorytmem Lanczos IrfanView a następnie rozpychanie lub odwrotnie zależy co lepiej wypadnie w testach wizualnych to współczynnik powiększenia wyniesie ąż x2 x1.6 czyli x3.2 a samym moim algorytmem w dwuch przebiegach 1x1.6x1.6=2.56 
i takie sklaowanie moim algorytmem materiału o rozdzielczości  SD w 2 przebiegach czyli 720x480 na przykład: 720x2.56=1843.2 | 480x2.56=1228.8 (1920 x1080 to FHD). Można powiedzieć że to idealne rozwiązanie a za razem najmniej skomplikowane a przy tym najbardziej dokładne z pośród dotychczas dostępnych aby otrzymać z rozdzielczości większości kanałów SD w DVB-T/S rozdzielczość prawie FullHD bo 1843.2x1228.8 jest też opcja PAL w Europie i Polsce SD 768x576i = po przemianach 1966.08 x 1474.56 .


https://github.com/devegoo/VED_CODE4CODEC4SCALE/blob/main/upraszczanie%20na%20porcjach%20danych.jpg
mamy tu w sumie 8 pozycji 12342413 a po jednoprzbiegowej kompresji w tym przypadku pozostało operant i pzycje kolejno : +1,+2,-5,1 wartość wejsciowa to pierwsza z puli do przebiegu kompresji mogłaby być oznaczona przedrostkiem 0 pozniej kolejno pozycje 1wartość,2wartosc,3wartosc,4wartosc a operant powtórzenia wartosci pozycji moglby byc zapisywany tam gdzie wystepuje jako podwójna komórka czyli bez przecinka zrobiloby sie poprostu 2 bity w ciągu co by było z automatu rozpoznawane, moc obliczeniowa potrzebna do tego bedzie zalezała od ilośći danych i ilorazu powtórzenia przebiegów , moze to byc uzyte w kompresji i dekompresji RealTime na bardzo słabym obliczeniowo cpu czyli na wszystkim co przychodzi na myśl


01 - 10 + 00 przedrostek wejsciowy
a wiem jeszcze lepiej jak to ułożyć aby były spójniejsze szeregi danych
01 bylby -
10 bylby +
00 poczatkowe dane
11 pozycja powtarzająca sie
czyli wstepnie ciag po pierwszym przbiegu z 1234,2413 do +1,+2-51 byłby widziany 10 1, 10 2 01 5 11 1
Decimal to Binary converter skonwertuje te wartości do ciągu 10 1 10 10 01 101 11 1
przy czym co druga wartość byłaby binarnie zapisana
i program do konpresji i dekompresji dzialalby w trybie mieszanym czyli pierwsza i kążda po-nastepna to znana wartość operanta a druga i każda po-następna to wartość binarna
12342413 - 101111000101010010001101
10 1 10 10 01 101 11 1 -xx1xx10xx101xx1-1101011
24 ciąg zredukowalem do 6 czyli ratio uzyskałem 4 do 1 bezstratnie




1 > 0 < 1 > 0 < 1 < 2 > 1 < 8 > 6 (>) > 0 > 0 > 1 > 6
AI Image processing" według mojego pomysłu na który wpadłem przed chwilą wyglądałby na coś w ten deseń że. dla wartości opisujących każdego pixela i sąsiadujące z nim w czterech kierunkach pixeli "+" można by było na tej wartości z pixela głownego i sąsiednich wypisać ciąg danych np 3(pixel głowny) - 2( pixel wrzedzie poprzedni) +1 (pixel w rzedzie kolejnym) -,- 4 (pixel w rzędzie poprzednim nad pixelem głownym) +,+6( pixel wrzedzie kolejnym pod pixelem głownym), Wtedy mamy taki ciąg danych:
 ,a3,b2,c1,d4,e6
i z takim ciągiem można robic co sie żywnie podoba stosując różne znane algorytmy matematyczne wg uznania , można zastosówać  wykrywanie w którym kierunku mając już kilka opisanych w zasobie np 32x32 px jest wzrost wartości rgb typu red green blue i ntej podstawie opisywać wektory potrzebne dla różnych filtrów które były by stosowane w rożnych celach np: w inteligentym podnoszeniu jakości zdjęć/grafik lub video , zbiór takich danych mógłby się przydać w AI paintingu processingu foto/video lub w wykrywać którym kierunku coś się porusza





Najprostsza porcja danych to będzie = zero (piksel nie podświetlony - czerń)
Najbardziej skomplikowana to kolor zapisany w 12 bit po dekompresji z 12 bit (kompresja zerowa)
Później stopień 75% 9 bit , 50% 6 bit i 25% 3 bit
Dla obrazu fullhd 1920x1080 pikseli = 2,073,600 pix , x 33,333 klatki /sekundę x 12 bit daje przy 100hz , 2073600x33,33,3x12= 829,431,706 cyferek 0/1 co wynosi /8 = 103,678,963 bajtów dalej / 1024 kilobajty = 101,248.987 kB / mb = 98.8759639 mb dla 100 klatek nieskompresowanych lub ok 25 mb dla 25 kl nieskompresowanych na sekundę full HD 25 % 6,25 50% 12,5 mb 75% 18,75 mb i 50% dla 1080i czyli 3,125mb (25%) - 9,375mb dla 75% kompresji max 12,50 mb

Wyniki X4 dla 4k , x16 dla 8k.
Czyli w najlepszym wypadku 8k 25% inerlaced = ok 50 Mbit/s do 200 Mbit nieskompresowany.
4k 25% intelaced = 12,5 Mbit/s
Dac miał kompresję zapisu stanu diody pomiedzy 0 , 3 bit a 12 bit a tu codec ma 4 bit np jak w tym przykładzie wynik 0 Hex 00 W tamtym przykładzie dla 33 klatek 100hz Dla obrazu fullhd 1920x1080 pikseli = 2,073,600 pix , x 33,333 klatki /sekundę x 4 bit daje 276477235,2 /8/1024/1024= 32,95 100% ok 4,11 Mbit/s 1080i 25% Czyli wg mojego kodeka obraz fullhd 1080i da się przesyłać na łączu 4-8 Mbit wynik dac musi miec przepustowosc dla 4k 25% intelaced = 12,5 Mbit/s a codec dla 4k i 16mbit/s 25(%) comp ratio dac 0,25 x x 32mb (4k 100%) =8 mb (przy comp 25x25) / interlaced 4 Mb = od 4-16 mb interlaced 4k lub 8 - 32mbit 4k progressive 4k da sie ogladac przy 12 mbit/sekunde ... To 1,5mb na dysku/d 60s 90 mb 1h = 540mb (4k interlaced ~75%comp) aha jeszcze zapomnialem o o algorytmie... constant/print  


UPDATE 2022/11/2

myslalem przed chwila wlasnie o nowej metodzie kompresji AI ale narazie dla ogolnego zastosowania ktora tez ma cechy AI jak ponizej w tym codec-u audio opublikowanym przez Meta EnCodec (facebook) i po dluzszych przemysleniach nad swoimi wczesniejszymi opracowywaniami w tej dziedzinie wymyslilem cos lepszego co by bylo zarowno i proste w implementacji i proste do zrozumienia . w tym nowym kodeku nie byloby tzw padow dla porcji danych bo odpowiednio podzielone porcje danych bylyby oczywiste dla dekompresora przez co porcja danych zmiejszy sie juz o ok 1/3 (haha) najzwyczajniej dekompresor rozpozna ze jest to ciag danych binarnych nalezacych do danej funkcji po strukturze tych danych czyli policzeniu ich , i jesli bedzie to wideo 16:9 to chyba jedyna informacja jaka mu bedzie potrzebna do odgadniecia to jest to gdzie konczy sie dajmy na to 1 sekunda (30 lub 60kl) dla pixela a to bedzie mogl odgadnac dekompresor z samego bitrate/sek z transmitowanego wideo, ale to jest jeszcze nie ten element AI , elementem AI w tym kodzie/prymitywie bedzie to ze beda tzw AI-unprisoned-flares-for-pull-off-pixels/data(0/1)-in-vectors-and-time (lava lamp)

o-x.jpg
Najprostszy przyklad/cwiczenie dla algorytmu kompresji AI o ktorej mowilem bedzie opracowanie jak najmniejszego a zarazem najszybszego kodu dla zakodowania a poznioej odkodowania toku rozgrywnki tej o to prostej gry kolko krzyzyk ale dowolnej tego typu rozgrywki czyli kod mosialby rozpoznac x / o i jakie sa kolejne pola wystepowania x / o i zapisac ten dowolny tok wystepowania jaknajszybciej i jak najmiej danych uzywajac . . .
w informatyce jest tak ze jak cos swietnie dziala na skeletonie/prymitywie to nie ma problemu aby dawalo rade w realiach
i jesli to sie uda zrobic to nastepnie mozna myslec juz o wiekszych i zarazem bardziej oblozonych strukturach danych

czyli gdyby to byla jedna sekunda wideo (5-klatek wideo o res 3:3)
i bylby to nawet nie czarno bialy obraz tylko kwadraty czarne i biale
tok postepowania dla 1 sekundy:
0.wykryc bitrate do czasu jednej sekundy i jesli jest on o jakiejs wielkosci stalej dla zdefiniowanych typow rozdzielczosci - proporcji zastosowac odpowiedni wariant algorytmu / preset
1.pule danych-T-Data(1s-Time) podzielic przez 5 (klatki-frames)
2.pol-Poles mamy =9 tak wiec =9 adresow -P-Adress dla kazdej klatki
3.pod kazdym z adresow P-Adress(1-9) kod wypisuje =0 dla pola bialego lub =1 dla pola czarnego np
 100000000, 100100000, 100100100, 110100100, 111100100
4. nastepnie dla kazdego z adresow wylicza jak zminial sie klatka po klatce
czyli 11111,00011,00001,01111,00000,00000,00010,00000,00000 ale to nam prawie nic nie jedynie jak mozna zauwazyc pojawilo sie  4 razy 000000 a wczesniej nie bylo takiego ujednolicenia/co wcale w realnym swiecie nie musi sie zdazyc
5. i tu tak naprawde tkwi sedno bo mamy w polu 9 polowym 81 kombinacji rozmieszczen czyli od 0-80 a w czasie czyli tych 9 polach w pieciu klatkach 81x5 = 405 kobinacji dla 5 klatek 
hahaha i mamy to ,
 czyli jak widzicie za pomoca jednego predefiniowanego patterna /zaadresowanej kombinacji dajmy na to 234 na przyklad adresu da sie wszystko z tych 9 pol i 5 klatek ogarnac do jedengo zapisu
w informatyce jest tak ze jak cos swietnie dziala na skeletonie/prymitywie to nie ma problemu aby dawalo rade w realiach
i jesli to sie uda zrobic to nastepnie mozna myslec juz o wiekszych i zarazem bardziej oblozonych strukturach danych


